from __future__ import division
import numpy as np
import gzip
import sys
import pickle
from scipy.misc import logsumexp
from scipy.optimize import minimize
import scipy.stats as stats
import scipy.optimize as opt
import clues
import glob
import h5py
from Bio import Phylo
from io import StringIO
import warnings
import argparse
warnings.filterwarnings("ignore")
parser = argparse.ArgumentParser(description=
                'CLUES calculates an estimate of the log-likelihood ratio of '+
                'selection along a grid of sites (fixed derived and/or segregating)'+
                'across a set of homologous sequences.')
parser.add_argument('logFile',type=str,help='The .log file generated by arg-sample; we use this to find out the time-discretization and popsize model used during ARG sampling.') 
parser.add_argument('transMatsDir',type=str,help='A folder containing .h5 files that contain transition probabilities + metadata for a set of discrete timesteps. Each .h5 file corresponds to a value of s')
parser.add_argument('-o','--output',dest='outFile',type=str,default=None)
parser.add_argument('-ssv','--ssv',action='store_true',help='Expands to test for sweeps from a standing variants (SSVs) and outputs estimates of t_s, f_s -- the time and frequency at which selection begins to act on the allele')
parser.add_argument('--tSelMax',type=float,default=10000)
parser.add_argument('-l','--listFreqs', nargs='+', help='List the frequencies that you would like to calc conditionals for', required=True)
parser.add_argument('--popsize',
            help = 'Effective popsize trajectory (file name). You only need to use this if you want to compute the likelihood under a different demographic model than used by ARGweaver during ARG sampling.',
            nargs = 2, metavar = ('popsize_file', 'popsize_transMatDir'),default=(None,None))
parser.add_argument('--debug',action='store_true')
parser.add_argument('--noSkip',action='store_true',help='check .log file; if 2x popsize lines, DONT use this option.')
args = parser.parse_args()
logFile = args.logFile
transMatDir = args.transMatsDir
outFile = args.outFile
popsizeFile = args.popsize[0]
popsizeTransMatDir = args.popsize[1]

def clean_trans_mat(mat):
	for (i,row) in enumerate(mat):
		row[row<=0] = 0
		row = row/np.sum(row)
		mat[i,:] = row
	return mat

def load_transition_probabilities(transMatDir,popsize,name=None):
        ## Load transition probabilities and create S_GRID and FREQS
        global S_GRID
        global I_SEL
        global FREQS
        global NG
        global BIN_EDGES

        LOG_TRANS_PROB_DICT = {}
        LOG_STAT_DISTN_DICT = {}
        S_GRID = []

        if args.debug:
                print('Loading transition mats...')

        def logdotexp(A, B):
                max_A = np.max(A)
                max_B = np.max(B)
                C = np.dot(np.exp(A - max_A), np.exp(B - max_B))
                np.log(C, out=C)
                C += max_A + max_B
                return C
        smin = 999

        for h5 in glob.glob(transMatDir+'*'):
                sstr = h5.split('s_')[1].split('.')[0]
                s = float(sstr.replace('p','.'))
                if s < smin:
                        smin = s
                        h5_neu = h5
        neu_mats = h5py.File(h5_neu,'r')
        FREQS = neu_mats.attrs['frequencies']
        NG = len(FREQS)   

        myFreqs = np.array([float(x) for x in args.listFreqs])
        freqIdxs  = np.sort(np.concatenate((np.digitize(myFreqs, FREQS, right=False),-1+np.digitize(myFreqs, FREQS, right=False))))
        freqIdxs = [_ for _ in freqIdxs if _ < len(FREQS)]
        if name != None:
        	f = h5py.File(name + '.' + args.outFile+'.hdf5','w')
        else:
                f = h5py.File( args.outFile+'.hdf5','w')

       # create list of times at which to test whether ssv started
        # if no ssv test: set t = [last timepoint] (i.e. only hard sweeps)
        if args.ssv:
                I_SEL = [i for i in range(0,len(np.diff(AW_TIMES))-1) if AW_TIMES[i+1] < args.tSelMax] + [len(np.diff(AW_TIMES)) - 1]
        else:
                I_SEL = [len(np.diff(AW_TIMES)) - 1]
        		
        logStatDistn = np.zeros((len(glob.glob(transMatDir+'*')),len(I_SEL),len(FREQS)))
        freqsDone = set([])
        for (i_d,discretizedPopFreqIdx) in enumerate(freqIdxs):
                discretizedPopFreqIdx = int(discretizedPopFreqIdx)
                if discretizedPopFreqIdx in freqsDone:
                        continue
                if args.debug: 
                        print('Conditioning on X(0) = %.3f'%(FREQS[discretizedPopFreqIdx]))
                S_GRID = []
                # create group; first level in hierarchy is conditioned frequency
                data = np.zeros((len(glob.glob(transMatDir+'*')),len(I_SEL),len(AW_TIMES) - 1, len(FREQS),len(FREQS)))
                for i_s,h5 in enumerate(glob.glob(transMatDir+'*')):
                        mats = h5py.File(h5,'r')
                        FREQS = mats.attrs['frequencies']
                        #import pdb; pdb.set_trace()
                        s = mats.attrs['s']
                        S_GRID.append(s)
                        for ii_sel,i_sel in enumerate(I_SEL):
                                if args.debug:
                                        print('Computing s = %.4f,\t SSV @ %d'%(s,AW_TIMES[i_sel]))
                                stat_distn_mat = np.log(np.eye(len(FREQS)))
                                stat_distn_mat[np.isnan(stat_distn_mat)] = -np.inf
                                for (i_dt,dt) in enumerate(np.diff(AW_TIMES)):
                                        #if args.debug:
                                        #       print('loading time %d, SSV @ %d, sel coeff %.4f'%(k,ii,s))
                                        N = popsize[i_dt]
                                        if i_dt > i_sel:
                                                if not args.ssv:
                                                        print("WRONG")
                                                mat = np.log(clean_trans_mat(np.array(neu_mats['P'+str(i_dt)])))
                                        else:
                                                mat = np.log(clean_trans_mat(np.array(mats['P'+str(i_dt)])))
                                        stat_distn_mat = logdotexp(mat,stat_distn_mat)
                                        if i_dt == 0:
                                                timeRemainingTrans = mat
                                        else:
                                                nextTimeRemainingTrans = logdotexp(mat,timeRemainingTrans)
                                        for (i_f0,f0) in enumerate(FREQS):
                                                for (i_f1,f1) in enumerate(FREQS):
                                                        if i_dt == 0:
                                                                if i_f1 == discretizedPopFreqIdx:
                                                                        data[i_s,ii_sel,i_dt,i_f0,i_f1] = 0
                                                                        #LOG_TRANS_PROB_DICT[(s,k,f0,f1,i_sel,discretizedPopFreqIdx)] = 0
                                                                else:
                                                                        data[i_s,ii_sel,i_dt,i_f0,i_f1] = -np.inf
                                                                        #LOG_TRANS_PROB_DICT[(s,k,f0,f1,i_sel,discretizedPopFreqIdx)] = -np.inf
                                                        else:
                                                                #CONDITIONAL ON PRESENT FREQ:
                                                                #print(mat[i,j], timeRemainingTrans[j,discretizedPopFreqIdx], nextTimeRemainingTrans[i,discretizedPopFreqIdx])
                                                                if False:
                                                                        data[i_s,ii_sel,i_dt,i_f0,i_f1] = mat[i_f0,i_f1]
                                                                        #LOG_TRANS_PROB_DICT[(s,k,f0,f1,i_sel,discretizedPopFreqIdx)] = mat[i,j]
                                                                else:
                                                                        data[i_s,ii_sel,i_dt,i_f0,i_f1] = mat[i_f0,i_f1] + timeRemainingTrans[i_f1,discretizedPopFreqIdx] - nextTimeRemainingTrans[i_f0,discretizedPopFreqIdx]
                                                                        #LOG_TRANS_PROB_DICT[(s,k,f0,f1,i_sel,discretizedPopFreqIdx)] = mat[i,j] + timeRemainingTrans[j,discretizedPopFreqIdx] - nextTimeRemainingTrans[i,discretizedPopFreqIdx]
                                                                #if np.isinf(LOG_TRANS_PROB_DICT[(s,dt,f0,f1)]):
                                                                #       import pdb; pdb.set_trace()
                                                                if np.isinf(data[i_s,ii_sel,i_dt,i_f0,i_f1]) or np.isnan(data[i_s,ii_sel,i_dt,i_f0,i_f1]):
                                                                        data[i_s,ii_sel,i_dt,i_f0,i_f1] = -np.inf
                                        if i_dt > 0:
                                                timeRemainingTrans = nextTimeRemainingTrans
                                        print(data[i_s,ii_sel,i_dt,:,:])		        
                                vec = -np.inf*np.ones(len(FREQS))
                                vec[0] = 0
                                stat_distn_vec = logdotexp(vec,stat_distn_mat)
                                logStatDistn[i_s,ii_sel,:] = stat_distn_vec
                I_s_sorted = np.argsort(S_GRID)
                data = data[I_s_sorted,:,:,:,:]
                S_GRID = np.sort(S_GRID)
                dset = f.create_dataset("trans_dpfi%d"%(discretizedPopFreqIdx), data=data, compression="gzip")
                freqsDone =  freqsDone | set([discretizedPopFreqIdx])
        f.attrs['sGrid'] = S_GRID
        f.attrs['iSel'] = I_SEL
        f.attrs['t'] = AW_TIMES
        f.attrs['freqs'] = FREQS
        f.attrs['popsize'] = popsize 
        statDistn = f.create_dataset("stat_distn", data=logStatDistn, compression="gzip")
        return 

def parse_log_file(logFile):
	## this step is crucial because it parameterizes the discrete-time model.
	## It sets two global variables:
	#		AW_TIMES (time discretization used by argweaver and clues)
	#		SAMPLING_POPSIZE (popsize used by argweaver)
	global AW_TIMES
	global SAMPLING_POPSIZE
	if logFile == '':
		## if no log file, we hard-code a default discretization (note this may be simply wrong
		AW_TIMES = np.array([0.000000,62.378528,163.667865,328.140000,595.207431,1028.867597,1733.038592,2876.461093,4733.133724,7747.971422,12643.420512,20592.578708,33500.304814,54459.680528,88493.206395,143756.344893,233491.815987,379202.953491,615806.554427,1000000.000000])
		SAMPLING_POPSIZE = np.array([10**4 for _ in AW_TIMES])
	else:	
		parsingPopsize = False
		for line in open(logFile,'r'):
			if len(line.split()) == 0:
				continue
			if line.split()[0] == 'times':
				AW_TIMES = np.array([float(x) for x in line.split()[2][1:][:-1].split(',')])
			if line.split()[0] == 'popsizes':
				parsingPopsize = True
				SAMPLING_POPSIZE = []
				if line.rstrip()[-1] == ']':
					SAMPLING_POPSIZE = np.array([float(x) for x in line.split()[2][1:][:-1].split(',')])
					break
				else:
					SAMPLING_POPSIZE = [float(line.split('[')[1].split(',')[0])]
					continue
			if parsingPopsize:
				SAMPLING_POPSIZE.append(float(line.rstrip()[:-1]))
				if line.rstrip()[-1] == ']':
					break
		SAMPLING_POPSIZE = SAMPLING_POPSIZE[::(2-int(args.noSkip))]
	return	
def parse_other_popsize(args):
	if popsizeFile == None:
		popsize = SAMPLING_POPSIZE
		reweightDemog = False
		N = popsize[0]
	elif popsizeFile != None:
		popsize = []
		for line in open(popsizeFile,'r'):
			## assumes that popsize file follows the same format
			## as required by argweaver
			cols = line.rstrip().split()
			popsize.append(float(cols[-1]))
		popsize = np.array(popsize)
		if np.sum(np.abs(popsize - SAMPLING_POPSIZE)) < 10**-8:
			print('WARNING: you appear to be reweighting using a demographic model identical to that used during ARG-sampling. This is redundant.')
		reweightDemog = True
		N = popsize[0]
	elif popsizeFile == None and args.N != None:
		N = args.N
		popsize = N * np.ones(len(SAMPLING_POPSIZE))
		reweightDemog = True
	else:
		raise ValueError('You cannot use both the --N and --popsize options. Please try again.')
	return popsize,reweightDemog

 ## load the arg-sample log to obtain time discretization and sampling popsize
parse_log_file(logFile)
ds = np.diff(AW_TIMES)
 ## parse extra popsize file (if provided, 
## i.e. want to calculate likelihood for diff. demog. model than under sampling)
popsize, reweightDemog = parse_other_popsize(args)
 #load frequency discretization
a = h5py.File(glob.glob(args.transMatsDir+'*.h5')[0],'r')
FREQS = a.attrs['frequencies']
 # load transition probabilities
load_transition_probabilities(transMatDir,SAMPLING_POPSIZE)
if reweightDemog:
	load_transition_probabilities(popsizeTransMatDir,popsize,name='reweight')
#for (i,s) in enumerate(S_GRID):
#	print(LOG_STAT_DISTN[(s,1)])
